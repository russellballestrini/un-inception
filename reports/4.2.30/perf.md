# Performance Report: 4.2.30

**Generated:** 2026-01-28T22:16:15Z
**Pipeline:** [#13299](https://git.unturf.com/engineering/unturf/un-inception/-/pipelines/13299)

## Summary

| Metric | Value |
|--------|-------|
| Total Tests | 840 |
| Passed | 839 |
| Failed | 1 |
| Pass Rate | 99.8% |
| Languages | 43 |
| Avg Duration | 161s |
| Slowest | julia (232s) |
| Fastest | ocaml (40s) |

---

## Test Duration by Language

The primary performance metric - how long each language takes to run its full test suite (15 tests per language).

![Duration by Language](chart-duration-by-language.png)

**Key observations:**
- **JULIA** and **HASKELL** are outliers at 90+ seconds
- Most languages cluster between 20-40 seconds
- Compiled languages (red) tend to be faster than interpreted (blue)
- **OCAML** is the fastest at 40 seconds

---

## Compiled vs Interpreted

Comparing performance between compiled languages (C, Go, Rust, etc.) and interpreted languages (Python, Ruby, JavaScript, etc.).

![Category Comparison](chart-category-comparison.png)

**Findings:**
- 20 compiled languages vs 22 interpreted
- Compiled languages have lower median execution time
- Interpreted languages show more variance (wider spread)
- The white diamond marks the mean for each category

---

## Duration Distribution

Histogram showing how test durations are distributed across all 43 languages.

![Duration Histogram](chart-duration-histogram.png)

**Distribution analysis:**
- Most languages complete in 20-35 seconds (the peak)
- Mean (green dashed) and median (blue dotted) are close together
- Long tail on the right from slow outliers (julia, haskell)

---

## Speed Leaders

Side-by-side comparison of the 10 slowest and 10 fastest languages.

![Speed Leaders](chart-speed-leaders.png)

**Slowest (left):** JULIA, HASKELL, FSHARP, DART, TCL
**Fastest (right):** OCAML, PYTHON, PHP, PERL, LUA

---

## Queue vs Execution Time

Scatter plot showing the relationship between CI queue wait time and actual test execution time.

![Queue vs Execution](chart-queue-vs-execution.png)

**Notes:**
- Queue time is how long the job waited for a runner
- Most jobs had similar queue times (clustered vertically)
- Outliers labeled - julia and haskell took longest to execute regardless of queue time

---

## Dashboard

Summary dashboard combining key metrics and visualizations.

![Dashboard](chart-dashboard.png)

---

## Raw Data

### Per-Language Performance

| Language | Status | Duration |
|----------|--------|----------|
| julia | Passed | 232s |
| haskell | Passed | 228s |
| fsharp | Passed | 228s |
| dart | Passed | 220s |
| tcl | Passed | 213s |
| scheme | Passed | 206s |
| objc | Passed | 202s |
| csharp | Passed | 192s |
| commonlisp | Passed | 190s |
| clojure | Passed | 189s |
| v | Passed | 188s |
| d | Passed | 187s |
| fortran | Passed | 185s |
| zig | Passed | 182s |
| nim | Passed | 181s |
| deno | Passed | 179s |
| raku | Passed | 176s |
| crystal | Passed | 175s |
| prolog | Passed | 174s |
| java | Passed | 171s |
| rust | Passed | 170s |
| kotlin | Passed | 170s |
| forth | Passed | 169s |
| erlang | Passed | 168s |
| bash | Passed | 164s |
| cobol | Passed | 162s |
| go | Passed | 160s |
| cpp | Passed | 160s |
| c | Passed | 154s |
| elixir | Passed | 138s |
| powershell | Passed | 136s |
| awk | Passed | 132s |
| javascript | Passed | 130s |
| groovy | Passed | 128s |
| r | Passed | 127s |
| ruby | Passed | 123s |
| typescript | Passed | 121s |
| dotnet | Passed | 121s |
| lua | Passed | 112s |
| perl | Passed | 96s |
| php | Passed | 86s |
| python | Passed | 60s |
| ocaml | Failed | 40s |

---

*Report generated by UN Inception CI pipeline*
